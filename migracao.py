import pandas as pd
from pymongo import MongoClient
import os
import unicodedata
from collections import defaultdict

# --- 1. CONFIGURA√á√ÉO E CONEX√ÉO ---
print("üöÄ Iniciando migra√ß√£o direta dos arquivos para MongoDB...")
try:
    # Conecta usando o nome do servi√ßo do docker-compose
    client = MongoClient('mongodb://mongo:27017/', serverSelectionTimeoutMS=5000)
    client.server_info()
    db = client['educacao_indigena']
    print("‚úÖ Conex√£o com MongoDB estabelecida com sucesso.")
except Exception as e:
    print(f"‚ùå Erro de conex√£o com MongoDB: {e}")
    exit()

# --- 2. FUN√á√ïES AUXILIARES E DE PROCESSAMENTO ---

def normalize_string(s):
    """Converte para mai√∫sculas, remove espa√ßos e acentos."""
    if not isinstance(s, str):
        return ""
    s = s.strip().upper()
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')

def processar_indicadores():
    """L√™ todos os arquivos XLSX e os processa em dicion√°rios prontos para uso."""
    print("... Processando arquivos de indicadores (.xlsx)...")
    try:
        df_frequencia = pd.read_excel('./datasets/frequencia_escolar.xlsx', header=None, skiprows=5)
        df_anos_estudo = pd.read_excel('./datasets/media_anos.xlsx', header=None, skiprows=5)
        df_instrucao = pd.read_excel('./datasets/nivel_instrucao.xlsx', header=None, skiprows=5)
    except FileNotFoundError as e:
        print(f"‚ùå Erro: Arquivo de indicador n√£o encontrado. Detalhes: {e}")
        return None, None, None

    uf_to_sigla = {
        'Rond√¥nia': 'RO', 'Acre': 'AC', 'Amazonas': 'AM', 'Roraima': 'RR',
        'Par√°': 'PA', 'Amap√°': 'AP', 'Tocantins': 'TO', 'Maranh√£o': 'MA',
        'Piau√≠': 'PI', 'Cear√°': 'CE', 'Rio Grande do Norte': 'RN', 'Para√≠ba': 'PB',
        'Pernambuco': 'PE', 'Alagoas': 'AL', 'Sergipe': 'SE', 'Bahia': 'BA',
        'Minas Gerais': 'MG', 'Esp√≠rito Santo': 'ES', 'Rio de Janeiro': 'RJ',
        'S√£o Paulo': 'SP', 'Paran√°': 'PR', 'Santa Catarina': 'SC',
        'Rio Grande do Sul': 'RS', 'Mato Grosso do Sul': 'MS', 'Mato Grosso': 'MT',
        'Goi√°s': 'GO', 'Distrito Federal': 'DF'
    }

    faixas_etarias_map = {
        '0 a 3 anos': 1, '4 a 5 anos': 2, '6 a 14 anos': 3,
        '15 a 17 anos': 4, '18 a 24 anos': 5, '25 anos ou mais': 6
    }

    # Processa Frequ√™ncia e Anos de Estudo
    frequencia_por_uf, anos_estudo_por_uf = {}, {}
    for df, target_dict, value_key in [(df_frequencia, frequencia_por_uf, "taxa"), (df_anos_estudo, anos_estudo_por_uf, "media_anos")]:
        df.columns = ['UF'] + [f'col_{i}' for i in range(1, len(df.columns))]
        for _, row in df.iterrows():
            if row['UF'] == 'Brasil' or pd.isna(row['UF']):
                continue
            sigla = uf_to_sigla.get(row['UF'])
            if not sigla:
                continue
            dados_para_uf = []
            for faixa, idx in faixas_etarias_map.items():
                col_name = f'col_{idx}'
                if col_name not in row or pd.isna(row[col_name]):
                    continue
                try:
                    valor_str = str(row[col_name]).replace(',', '.').strip()
                    if valor_str in ['-', '', 'X', '..', '...']:
                        continue
                    dados_para_uf.append({"faixa_etaria": faixa, value_key: float(valor_str)})
                except (ValueError, TypeError):
                    continue
            target_dict[sigla] = dados_para_uf

    # ===== CORRE√á√ÉO: Processa N√≠vel de Instru√ß√£o =====
    print("üîç Debug: Processando n√≠vel de instru√ß√£o...")
    print(f"üîç Debug: Dataframe tem {len(df_instrucao)} linhas e {len(df_instrucao.columns)} colunas")

    instrucao_por_municipio = defaultdict(list)

    # Defini√ß√µes corretas baseadas no c√≥digo PostgreSQL
    niveis_instrucao = [
        'Sem instru√ß√£o e fundamental incompleto',
        'Fundamental completo e m√©dio incompleto',
        'M√©dio completo e superior incompleto',
        'Superior completo'
    ]

    faixas_etarias_inst = [
        'Total', '18 a 24 anos', '18 a 19 anos', '20 a 24 anos',
        '25 anos ou mais', '25 a 64 anos', '25 a 29 anos', '30 a 34 anos',
        '35 a 39 anos', '40 a 44 anos', '45 a 49 anos', '50 a 54 anos',
        '55 a 59 anos', '60 a 64 anos', '65 anos ou mais', '65 a 69 anos',
        '70 a 74 anos', '75 a 79 anos', '80 anos ou mais'
    ]

    # Mapeamento para nomes abreviados
    nivel_abreviado = {
        'Sem instru√ß√£o e fundamental incompleto': 'Sem instru√ß√£o',
        'Fundamental completo e m√©dio incompleto': 'Fundamental completo',
        'M√©dio completo e superior incompleto': 'M√©dio completo',
        'Superior completo': 'Superior completo'
    }

    linhas_processadas = 0
    registros_inseridos = 0

    # Processar cada linha do DataFrame
    for idx, row in df_instrucao.iterrows():
        # Verificar se a primeira c√©lula cont√©m um nome v√°lido
        if pd.isna(row[0]) or not isinstance(row[0], str):
            continue

        nome_local = str(row[0]).strip()

        # Pular totais nacionais
        if nome_local == 'Brasil':
            continue

        # Normalizar nome do munic√≠pio
        nome_municipio_normalizado = normalize_string(nome_local)
        if not nome_municipio_normalizado:
            continue

        linhas_processadas += 1
        if linhas_processadas <= 5:  # Debug apenas dos primeiros 5
            print(f"üîç Debug: Processando munic√≠pio {linhas_processadas}: {nome_local} -> {nome_municipio_normalizado}")

        # Para cada n√≠vel de instru√ß√£o
        for nivel_idx, nivel_original in enumerate(niveis_instrucao):
            # Calcular deslocamento das colunas para este n√≠vel
            col_offset = 1 + (len(faixas_etarias_inst) * nivel_idx)

            # Para cada faixa et√°ria
            for faixa_idx, faixa in enumerate(faixas_etarias_inst):
                col_num = col_offset + faixa_idx

                # Verificar se a coluna existe
                if col_num >= len(row):
                    continue

                valor = row[col_num]

                # Verificar se o valor √© v√°lido
                if pd.isna(valor):
                    continue

                try:
                    # Converter valor para string e limpar
                    valor_str = str(valor).strip()

                    # Pular valores inv√°lidos
                    if valor_str in ['-', '', 'X', '..', '...']:
                        continue

                    # Converter para n√∫mero
                    qt_pessoas = int(float(valor_str))

                    # Se chegou at√© aqui, √© um valor v√°lido
                    nivel_para_inserir = nivel_abreviado[nivel_original]

                    instrucao_por_municipio[nome_municipio_normalizado].append({
                        "faixa_etaria": faixa,
                        "nivel": nivel_para_inserir,
                        "qt_pessoas": qt_pessoas
                    })

                    registros_inseridos += 1

                except (ValueError, TypeError) as e:
                    if linhas_processadas <= 5:  # Debug apenas dos primeiros 5
                        print(f"‚ö†Ô∏è  Erro ao processar valor '{valor}' para {nome_local}, n√≠vel {nivel_original}, faixa {faixa}: {e}")
                    continue

    print(f"‚úÖ N√≠vel de instru√ß√£o processado: {linhas_processadas} munic√≠pios, {registros_inseridos} registros")
    print(f"üîç Debug: Dicion√°rio final tem {len(instrucao_por_municipio)} munic√≠pios com dados")

    # Debug: mostrar alguns munic√≠pios processados
    for i, (municipio, dados) in enumerate(instrucao_por_municipio.items()):
        if i < 3:  # Mostrar apenas os 3 primeiros
            print(f"üîç Debug: {municipio} tem {len(dados)} registros de instru√ß√£o")

    return frequencia_por_uf, anos_estudo_por_uf, instrucao_por_municipio

# --- 3. FUN√á√ÉO PRINCIPAL DE MIGRA√á√ÉO ---
def run_migration():
    """L√™ os arquivos de origem, transforma os dados e os insere no MongoDB."""
    try:
        df_censo = pd.read_csv('./datasets/microdados_ed_basica_2023.csv', sep=';', low_memory=False, encoding='latin1')
        colunas_para_zerar = ['QT_MAT_BAS', 'QT_MAT_BAS_INDIGENA', 'QT_TUR_INF', 'QT_TUR_FUND', 'QT_TUR_MED', 'QT_TUR_EJA', 'NU_ANO_CENSO', 'IN_INF', 'IN_FUND_AI', 'IN_FUND_AF', 'IN_MED', 'IN_EJA']
        for col in colunas_para_zerar:
            if col in df_censo.columns:
                df_censo[col] = pd.to_numeric(df_censo[col], errors='coerce').fillna(0)
    except FileNotFoundError as e:
        print(f"‚ùå Erro fatal: Arquivo 'microdados_ed_basica_2023.csv' n√£o encontrado. Detalhes: {e}")
        return

    # Processar indicadores
    frequencia_por_uf, anos_estudo_por_uf, instrucao_por_municipio = processar_indicadores()

    if instrucao_por_municipio is None:
        print("‚ùå Erro fatal: N√£o foi poss√≠vel processar os indicadores.")
        return

    # Debug tempor√°rio - verificar correspond√™ncia de nomes
    print("\nüîç TESTE: Primeiros 5 munic√≠pios do arquivo de instru√ß√£o:")
    for i, municipio in enumerate(list(instrucao_por_municipio.keys())[:5]):
        print(f"  {i+1}. {municipio} -> {len(instrucao_por_municipio[municipio])} registros")

    # --- Migra√ß√£o de Munic√≠pios ---
    print("\nüèõÔ∏è  Migrando Munic√≠pios...")
    db.Municipios.drop()
    municipios_agrupados = df_censo.groupby('CO_MUNICIPIO').agg(
        nome_municipio=('NO_MUNICIPIO', 'first'),
        uf_sigla=('SG_UF', 'first'),
        regiao_nome=('NO_REGIAO', 'first'),
        populacao_total=('QT_MAT_BAS', 'sum'),
        populacao_indigena=('QT_MAT_BAS_INDIGENA', 'sum')
    ).reset_index()

    print(f"\nüîç TESTE: Primeiros 5 munic√≠pios do censo:")
    for i, municipio in enumerate(municipios_agrupados['nome_municipio'].head()):
        normalizado = normalize_string(municipio)
        tem_dados = "SIM" if normalizado in instrucao_por_municipio else "N√ÉO"
        print(f"  {i+1}. {municipio} -> {normalizado} -> Tem dados: {tem_dados}")

    municipios_docs, municipio_map = [], {}
    municipios_com_instrucao = 0

    for _, row in municipios_agrupados.iterrows():
        nome_normalizado = normalize_string(row['nome_municipio'])

        # Buscar dados de instru√ß√£o para este munic√≠pio
        dados_instrucao = instrucao_por_municipio.get(nome_normalizado, [])

        if dados_instrucao:
            municipios_com_instrucao += 1
            if municipios_com_instrucao <= 5:  # Debug apenas dos primeiros 5
                print(f"‚úÖ Munic√≠pio {row['nome_municipio']} ({nome_normalizado}) tem {len(dados_instrucao)} registros de instru√ß√£o")

        doc = {
            "nome_municipio": row['nome_municipio'],
            "uf_sigla": row['uf_sigla'],
            "regiao_nome": row['regiao_nome'],
            "populacao_total": int(row['populacao_total']),
            "populacao_indigena": int(row['populacao_indigena']),
            "indicadores_educacionais": {
                "frequencia_escolar": frequencia_por_uf.get(row['uf_sigla'], []),
                "anos_estudo": anos_estudo_por_uf.get(row['uf_sigla'], []),
                "nivel_instrucao": dados_instrucao
            }
        }
        municipios_docs.append(doc)

    print(f"üîç Debug: {municipios_com_instrucao} munic√≠pios t√™m dados de instru√ß√£o de um total de {len(municipios_agrupados)}")

    if municipios_docs:
        result = db.Municipios.insert_many(municipios_docs)
        for i, row in municipios_agrupados.iterrows():
            municipio_map[int(row['CO_MUNICIPIO'])] = result.inserted_ids[i]

    print(f"‚úÖ {len(municipio_map)} munic√≠pios migrados.")

    # --- Migra√ß√£o de Escolas ---
    print("\nüè´ Migrando Escolas...")
    db.Escolas.drop()
    escolas_df = df_censo.drop_duplicates(subset='CO_ENTIDADE')
    escolas_docs = []
    dep_map = {1: 'Federal', 2: 'Estadual', 3: 'Municipal', 4: 'Privada'}
    loc_map = {1: 'Urbana', 2: 'Rural'}
    sit_map = {1: 'Ativa', 2: 'Inativa', 3: 'Paralisada'}

    for _, row in escolas_df.iterrows():
        id_municipio_mongo = municipio_map.get(int(row['CO_MUNICIPIO']))
        if not id_municipio_mongo:
            continue

        turmas = [
            {"nivel_ensino": "Infantil", "qt_turmas": int(row['QT_TUR_INF'])},
            {"nivel_ensino": "Fundamental", "qt_turmas": int(row['QT_TUR_FUND'])},
            {"nivel_ensino": "M√©dio", "qt_turmas": int(row['QT_TUR_MED'])}
        ]
        turmas = [t for t in turmas if t['qt_turmas'] > 0]

        niveis_ofertados = [n for f, n in [(row['IN_INF'], "Infantil"), (row['IN_FUND_AI'] or row['IN_FUND_AF'], "Fundamental"), (row['IN_MED'], "M√©dio")] if f]

        matriculas = [{
            "ano_referencia": int(row['NU_ANO_CENSO']),
            "niveis_ofertados": niveis_ofertados,
            "qt_matriculas_total": int(row['QT_MAT_BAS']),
            "qt_matriculas_indigenas": int(row['QT_MAT_BAS_INDIGENA'])
        }] if niveis_ofertados else []

        doc = {
            "nome_escola": row['NO_ENTIDADE'],
            "municipio_id": id_municipio_mongo,
            "uf_sigla": row['SG_UF'],
            "regiao_nome": row['NO_REGIAO'],
            "tipo_dependencia": dep_map.get(row['TP_DEPENDENCIA'], 'NI'),
            "tipo_localizacao": loc_map.get(row['TP_LOCALIZACAO'], 'NI'),
            "situacao_funcionamento": sit_map.get(row['TP_SITUACAO_FUNCIONAMENTO'], 'NI'),
            "indigena": bool(row['IN_EDUCACAO_INDIGENA']),
            "turmas": turmas,
            "matriculas": matriculas
        }
        escolas_docs.append(doc)

    if escolas_docs:
        db.Escolas.insert_many(escolas_docs)
    print(f"‚úÖ {len(escolas_docs)} escolas migradas.")

    # --- Migra√ß√£o de Territ√≥rios Ind√≠genas ---
    print("\nüèûÔ∏è  Migrando Territ√≥rios Ind√≠genas...")
    db.TerritoriosIndigenas.drop()
    df_territorios = df_censo[df_censo['TP_LOCALIZACAO_DIFERENCIADA'] == 1].copy().drop_duplicates(subset=['NO_MUNICIPIO', 'SG_UF'])
    territorios_docs = [{
        "nome_territorio": f"Territ√≥rio Ind√≠gena em {row['NO_MUNICIPIO']}",
        "uf_sigla": row['SG_UF'],
        "regiao_nome": row['NO_REGIAO']
    } for _, row in df_territorios.iterrows()]

    if territorios_docs:
        db.TerritoriosIndigenas.insert_many(territorios_docs)
    print(f"‚úÖ {len(territorios_docs)} territ√≥rios ind√≠genas migrados.")

    # --- Verifica√ß√£o final ---
    print("\nüîç Verifica√ß√£o final dos dados inseridos:")

    # Contar munic√≠pios com dados de instru√ß√£o no MongoDB
    municipios_com_dados = db.Municipios.count_documents({
        "indicadores_educacionais.nivel_instrucao": {"$ne": []}
    })

    print(f"üìä Munic√≠pios no MongoDB com dados de instru√ß√£o: {municipios_com_dados}")

    # Mostrar exemplo de munic√≠pio com dados
    exemplo = db.Municipios.find_one({
        "indicadores_educacionais.nivel_instrucao": {"$ne": []}
    })

    if exemplo:
        print(f"üìã Exemplo - {exemplo['nome_municipio']} tem {len(exemplo['indicadores_educacionais']['nivel_instrucao'])} registros de instru√ß√£o")
    else:
        print("‚ùå Nenhum munic√≠pio encontrado com dados de instru√ß√£o!")

# --- 4. EXECU√á√ÉO ---
if __name__ == "__main__":
    try:
        run_migration()
        print("\n\nüéâ Migra√ß√£o DIRETA DOS ARQUIVOS conclu√≠da com sucesso!")
    except Exception as e:
        print(f"\n‚ùå Ocorreu um erro geral durante a migra√ß√£o: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if 'client' in locals() and client:
            client.close()
            print("\nüîå Conex√£o com MongoDB fechada.")